<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta content="Apache Forrest" name="Generator">
<meta name="Forrest-version" content="0.8">
<meta name="Forrest-skin-name" content="pelt">
<title>Pig Cookbook</title>
<link type="text/css" href="skin/basic.css" rel="stylesheet">
<link media="screen" type="text/css" href="skin/screen.css" rel="stylesheet">
<link media="print" type="text/css" href="skin/print.css" rel="stylesheet">
<link type="text/css" href="skin/profile.css" rel="stylesheet">
<script src="skin/getBlank.js" language="javascript" type="text/javascript"></script><script src="skin/getMenu.js" language="javascript" type="text/javascript"></script><script src="skin/fontsize.js" language="javascript" type="text/javascript"></script>
<link rel="shortcut icon" href="">
</head>
<body onload="init()">
<script type="text/javascript">ndeSetTextSize();</script>
<div id="top">
<!--+
    |breadtrail
    +-->
<div class="breadtrail">
<a href="http://www.apache.org/">Apache</a> &gt; <a href="http://hadoop.apache.org/">Hadoop</a> &gt; <a href="http://hadoop.apache.org/pig/">Pig</a><script src="skin/breadcrumbs.js" language="JavaScript" type="text/javascript"></script>
</div>
<!--+
    |header
    +-->
<div class="header">
<!--+
    |start group logo
    +-->
<div class="grouplogo">
<a href="http://hadoop.apache.org/"><img class="logoImage" alt="Hadoop" src="images/hadoop-logo.jpg" title="Apache Hadoop"></a>
</div>
<!--+
    |end group logo
    +-->
<!--+
    |start Project Logo
    +-->
<div class="projectlogo">
<a href="http://hadoop.apache.org/pig/"><img class="logoImage" alt="Pig" src="images/pig-logo.gif" title="A platform for analyzing large datasets."></a>
</div>
<!--+
    |end Project Logo
    +-->
<!--+
    |start Search
    +-->
<div class="searchbox">
<form action="http://www.google.com/search" method="get" class="roundtopsmall">
<input value="" name="sitesearch" type="hidden"><input onFocus="getBlank (this, 'Search the site with google');" size="25" name="q" id="query" type="text" value="Search the site with google">&nbsp; 
                    <input name="Search" value="Search" type="submit">
</form>
</div>
<!--+
    |end search
    +-->
<!--+
    |start Tabs
    +-->
<ul id="tabs">
<li>
<a class="unselected" href="http://hadoop.apache.org/pig/">Project</a>
</li>
<li>
<a class="unselected" href="http://wiki.apache.org/pig/">Wiki</a>
</li>
<li class="current">
<a class="selected" href="index.html">Pig 0.5.0 Documentation</a>
</li>
</ul>
<!--+
    |end Tabs
    +-->
</div>
</div>
<div id="main">
<div id="publishedStrip">
<!--+
    |start Subtabs
    +-->
<div id="level2tabs"></div>
<!--+
    |end Endtabs
    +-->
<script type="text/javascript"><!--
document.write("Last Published: " + document.lastModified);
//  --></script>
</div>
<!--+
    |breadtrail
    +-->
<div class="breadtrail">

             &nbsp;
           </div>
<!--+
    |start Menu, mainarea
    +-->
<!--+
    |start Menu
    +-->
<div id="menu">
<div onclick="SwitchMenu('menu_1.1', 'skin/')" id="menu_1.1Title" class="menutitle">Getting Started</div>
<div id="menu_1.1" class="menuitemgroup">
<div class="menuitem">
<a href="index.html">Overview</a>
</div>
<div class="menuitem">
<a href="setup.html">Setup</a>
</div>
<div class="menuitem">
<a href="tutorial.html">Tutorial</a>
</div>
</div>
<div onclick="SwitchMenu('menu_selected_1.2', 'skin/')" id="menu_selected_1.2Title" class="menutitle" style="background-image: url('skin/images/chapter_open.gif');">Guides</div>
<div id="menu_selected_1.2" class="selectedmenuitemgroup" style="display: block;">
<div class="menuitem">
<a href="piglatin_users.html">Pig Latin Users </a>
</div>
<div class="menuitem">
<a href="piglatin_reference.html">Pig Latin Reference</a>
</div>
<div class="menupage">
<div class="menupagetitle">Cookbook</div>
</div>
<div class="menuitem">
<a href="udf.html">UDFs</a>
</div>
</div>
<div onclick="SwitchMenu('menu_1.3', 'skin/')" id="menu_1.3Title" class="menutitle">Miscellaneous</div>
<div id="menu_1.3" class="menuitemgroup">
<div class="menuitem">
<a href="http://hadoop.apache.org/pig/docs/r0.5.0/api/">API Docs</a>
</div>
<div class="menuitem">
<a href="http://wiki.apache.org/pig/">Wiki</a>
</div>
<div class="menuitem">
<a href="http://wiki.apache.org/pig/FAQ">FAQ</a>
</div>
<div class="menuitem">
<a href="http://hadoop.apache.org/pig/releases.html">Release Notes</a>
</div>
</div>
<div id="credit"></div>
<div id="roundbottom">
<img style="display: none" class="corner" height="15" width="15" alt="" src="skin/images/rc-b-l-15-1body-2menu-3menu.png"></div>
<!--+
  |alternative credits
  +-->
<div id="credit2"></div>
</div>
<!--+
    |end Menu
    +-->
<!--+
    |start content
    +-->
<div id="content">
<div title="Portable Document Format" class="pdflink">
<a class="dida" href="cookbook.pdf"><img alt="PDF -icon" src="skin/images/pdfdoc.gif" class="skin"><br>
        PDF</a>
</div>
<h1>Pig Cookbook</h1>
<div id="minitoc-area">
<ul class="minitoc">
<li>
<a href="#Overview">Overview</a>
</li>
<li>
<a href="#Performance+Enhancers">Performance Enhancers</a>
<ul class="minitoc">
<li>
<a href="#Use+Optimization">Use Optimization</a>
</li>
<li>
<a href="#Use+Types">Use Types</a>
</li>
<li>
<a href="#Project+Early+and+Often">Project Early and Often </a>
</li>
<li>
<a href="#Filter+Early+and+Often">Filter Early and Often</a>
</li>
<li>
<a href="#Reduce+Your+Operator+Pipeline">Reduce Your Operator Pipeline</a>
</li>
<li>
<a href="#Make+your+UDFs+Algebraic">Make your UDFs Algebraic</a>
</li>
<li>
<a href="#Drop+Nulls+Before+a+Join">Drop Nulls Before a Join</a>
</li>
<li>
<a href="#Take+Advantage+of+Join+Optimization">Take Advantage of Join Optimization</a>
</li>
<li>
<a href="#Use+Fragment+Replicate+Join">Use Fragment Replicate Join</a>
</li>
<li>
<a href="#Use+PARALLEL+Keyword">Use PARALLEL Keyword</a>
</li>
<li>
<a href="#Use+LIMIT">Use LIMIT</a>
</li>
<li>
<a href="#Prefer+DISTINCT+over+GROUP+BY+-+GENERATE">Prefer DISTINCT over GROUP BY - GENERATE</a>
</li>
</ul>
</li>
</ul>
</div>


<a name="N1000D"></a><a name="Overview"></a>
<h2 class="h3">Overview</h2>
<div class="section">
<p>This document provides hints and tips for pig users. </p>
</div>


<a name="N10017"></a><a name="Performance+Enhancers"></a>
<h2 class="h3">Performance Enhancers</h2>
<div class="section">
<a name="N1001D"></a><a name="Use+Optimization"></a>
<h3 class="h4">Use Optimization</h3>
<p>Pig supports various <a href="piglatin_users.html#Optimization+Rules">optimization rules</a> which are turned on by default. 
Become familiar with these rules.</p>
<a name="N1002B"></a><a name="Use+Types"></a>
<h3 class="h4">Use Types</h3>
<p>If types are not specified in the load statement, Pig assumes the type of =double= for numeric computations. 
A lot of the time, your data would be much smaller, maybe, integer or long. Specifying the real type will help with 
speed of arithmetic computation. It has an additional advantage of early error detection. </p>
<pre class="code">
--Query 1
A = load 'myfile' as (t, u, v);
B = foreach A generate t + u;

--Query 2
A = load 'myfile' as (t: int, u: int, v);
B = foreach A generate t + u;
</pre>
<p>The second query will run more efficiently than the first. In some of our queries with see 2x speedup. </p>
<a name="N1003C"></a><a name="Project+Early+and+Often"></a>
<h3 class="h4">Project Early and Often </h3>
<p>Pig does not (yet) determine when a field is no longer needed and drop the field from the row.  For example, say you have a query like: </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = load 'myotherfile' as (x, y, z);
C = join A by t, B by x;
D = group C by u;
E = foreach D generate group, COUNT($1);
</pre>
<p>There is no need for v, y, or z to participate in this query.  And there is no need to carry both t and x past the join, just one will suffice.  Changing the above query to  </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
A1 = foreach A generate t, u;
B = load 'myotherfile' as (x, y, z);
B1 = foreach B generate x;
C = join A1 by t, B1 by x;
C1 = foreach C generate t, u;
D = group C1 by u;
E = foreach D generate group, COUNT($1);
</pre>
<p>will greatly reduce the amount of data being carried through the map and reduce phases by pig.  Depending on your data, this can produce significant time savings.  In queries similar to the example given we have seen total time drop by 50%. </p>
<a name="N10054"></a><a name="Filter+Early+and+Often"></a>
<h3 class="h4">Filter Early and Often</h3>
<p>As with early projection, in most cases it is beneficial to apply filters as early as possible to reduce the amount of data flowing through the pipeline. </p>
<pre class="code">
-- Query 1
A = load 'myfile' as (t, u, v);
B = load 'myotherfile' as (x, y, z);
C = filter A by t == 1;
D = join C by t, B by x;
E = group D by u;
F = foreach E generate group, COUNT($1);

-- Query 2
A = load 'myfile' as (t, u, v);
B = load 'myotherfile' as (x, y, z);
C = join A by t, B by x;
D = group C by u;
E = foreach D generate group, COUNT($1);
F = filter E by C.t == 1;
</pre>
<p>The first query is clearly more efficient than the second one because it reduces the amount of data going into the join. </p>
<p>One case where pushing filters up might not be a good idea is if the cost of applying filter is very high and only a small amount of data is filtered out. </p>
<a name="N10068"></a><a name="Reduce+Your+Operator+Pipeline"></a>
<h3 class="h4">Reduce Your Operator Pipeline</h3>
<p>For clarity of your script, you might choose to split your projects into several steps for instance: </p>
<pre class="code">
A = load 'data' as (in: map[]);
-- get key out of the map
B = foreach A generate in#k1 as k1, in#k2 as k2;
-- concatenate the keys
C = foreach B generate CONCAT(k1, k2);
.......
</pre>
<p>While the example above is easier to read, you might want to consider combining the two foreach statements to improve your query performance: </p>
<pre class="code">
A = load 'data' as (in: map[]);
-- concatenate the keys from the map
B = foreach A generate CONCAT(in#k1, in#k2);
....
</pre>
<p>The same goes for filters. </p>
<a name="N10080"></a><a name="Make+your+UDFs+Algebraic"></a>
<h3 class="h4">Make your UDFs Algebraic</h3>
<p>Queries that can take advantage of the combiner generally ran much faster (sometimes several times faster) than the versions that don't. 
The latest code significantly improves combiner usage; however, you need to make sure you do your part. 
If you have a UDF that works on grouped data and is, by nature, algebraic (meaning their computation can be decomposed into multiple steps) 
make sure you implement it as such. For details on how to write algebraic UDFs, see the <a href="udf.html">Pig UDF Manual</a>. </p>
<pre class="code">
A = load 'data' as (x, y, z)
B = group A by x;
C = foreach B generate group, MyUDF(A);
....
</pre>
<p>If <span class="codefrag">MyUDF</span> is algebraic, the query will use combiner and run much faster. You can run <span class="codefrag">explain</span> command on your query to make sure that combiner is used. </p>
<a name="N1009B"></a><a name="Drop+Nulls+Before+a+Join"></a>
<h3 class="h4">Drop Nulls Before a Join</h3>
<p>This comment only applies to pig 0.2.0 branch, as pig 0.1.0 does not have nulls. </p>
<p>With the introduction of nulls, join and cogroup semantics were altered to work with nulls.  The semantic for cogrouping with nulls is that nulls from a given input are grouped together, but nulls across inputs are not grouped together.  This preserves the semantics of grouping (nulls are collected together from a single input to be passed to aggregate functions like COUNT) and the semantics of join (nulls are not joined across inputs).  Since flattening an empty bag results in an empty row, in a standard join the rows with a null key will always be dropped.  The join:  </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = load 'myotherfile' as (x, y, z);
C = join A by t, B by x;
</pre>
<p>is rewritten by pig to </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = load 'myotherfile' as (x, y, z);
C1 = cogroup A by t INNER, B by x INNER;
C = foreach C1 generate flatten(A), flatten(B);
</pre>
<p>Since the nulls from A and B won't be collected together, when the nulls are flattened we're guaranteed to have an empty bag, which will result in no output.  So the null keys will be dropped.  But they will not be dropped until the last possible moment.  If the query is rewritten to </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = load 'myotherfile' as (x, y, z);
A1 = filter A by t is not null;
B1 = filter B by x is not null;
C = join A1 by t, B1 by x;
</pre>
<p>then the nulls will be dropped before the join.  Since all null keys go to a single reducer, if your key is null even a small percentage of the time the gain can be significant.  In one test where the key was null 7% of the time and the data was spread across 200 reducers, we saw a about a 10x speed up in the query by adding the early filters. </p>
<a name="N100BD"></a><a name="Take+Advantage+of+Join+Optimization"></a>
<h3 class="h4">Take Advantage of Join Optimization</h3>
<p>The optimization insures that the last table in the join is not brought into memory but stream through instead. The optimization reduces the amount of memory used which means you can avoid spilling the data and also should be able to scale your query to larger data volumes. </p>
<p>To take advantage of this optimization, make sure that the table with the largest number of tuples per key is the last table in your query. </p>
<pre class="code">
small = load 'small_file' as (t, u, v);
large = load 'large_file' as (x, y, z);
C = join small by t, large by x;
</pre>
<p>In some of our tests we saw 10x performance improvement as the result of this optimization. </p>
<a name="N100D1"></a><a name="Use+Fragment+Replicate+Join"></a>
<h3 class="h4">Use Fragment Replicate Join</h3>
<p>This type of join works well if one of tables is small enough to fit into main memory. In this case, Pig can perform a very efficient join since, in hadoop world, it can be done completely on the map side. </p>
<pre class="code">
tiny = load 'small_file' as (t, u, v);
large = load 'large_file' as (x, y, z);
C = join large by x, tiny by t using "replicated";
</pre>
<p>Note that the large table must come first followed by one or more small tables. All small tables together must fit into main memory. </p>
<p>This feature is new and experimental. It is experimental because we don't have a strong sense of how small the small table must be to fit into memory. In our tests with a simple query that involved just join a table of up to 100M can be used if the process overall gets 1 GB of memory. If the table does not fit into memory, the process would fail and generate an error. </p>
<a name="N100E5"></a><a name="Use+PARALLEL+Keyword"></a>
<h3 class="h4">Use PARALLEL Keyword</h3>
<p>PARALLEL controls the number of reducers invoked by Hadoop. The default out of the box is 1 which, in most cases, is not what you want. I reasonable heuristic to use is something like  </p>
<pre class="code">&lt;num machines&gt; * &lt;num reduce slots per machine&gt; * 0.9</pre>
<p>The keyword makes sense on any operator that starts a reduce phase. This includes GROUP, COGROUP, JOIN, DISTINCT, LIMIT, ORDER BY. </p>
<p>Example: </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = group A by t PARALLEL 18;
.....
</pre>
<a name="N100FD"></a><a name="Use+LIMIT"></a>
<h3 class="h4">Use LIMIT</h3>
<p>A lot of the times, you are not interested in the entire output but either a sample or top results. In those cases, using LIMIT can yeild a much better performance as we push the limit as high as possible to minimize the amount of data travelling through the pipeline. </p>
<p>Sample: 
</p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = limit A 500;
</pre>
<p>Top results: </p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = order A by t;
C = limit B 500;
</pre>
<a name="N10115"></a><a name="Prefer+DISTINCT+over+GROUP+BY+-+GENERATE"></a>
<h3 class="h4">Prefer DISTINCT over GROUP BY - GENERATE</h3>
<p>When it comes to extracting the unique values from a column in a relation, one of two approaches can be used: </p>
<p>Example Using GROUP BY - GENERATE</p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = foreach A generate u;
C = group B by u;
D = foreach C generate group as uniquekey;
dump D; 
</pre>
<p>Example Using DISTINCT</p>
<pre class="code">
A = load 'myfile' as (t, u, v);
B = foreach A generate u;
C = distinct B;
dump C; 
</pre>
<p>In pig 0.1.x, DISTINCT is just GROUP BY/PROJECT under the hood. In pig 0.2.0 it is not, and it is much faster and more efficient (depending on your key cardinality, up to 20x faster in pig team's tests). Therefore, the use of DISTINCT is recommended over GROUP BY - GENERATE.  </p>
</div>

</div>
<!--+
    |end content
    +-->
<div class="clearboth">&nbsp;</div>
</div>
<div id="footer">
<!--+
    |start bottomstrip
    +-->
<div class="lastmodified">
<script type="text/javascript"><!--
document.write("Last Published: " + document.lastModified);
//  --></script>
</div>
<div class="copyright">
        Copyright &copy;
         2007-2010 <a href="http://www.apache.org/licenses/">The Apache Software Foundation.</a>
</div>
<!--+
    |end bottomstrip
    +-->
</div>
</body>
</html>
